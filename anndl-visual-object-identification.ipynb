{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "# Set the seed for random operations. \n",
    "# This let our experiments to be reproducible. \n",
    "SEED = 1234\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Get current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Set GPU memory growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare envinromment useful variables\n",
    "\n",
    "# Get current working directory\n",
    "cwd = os.path.join(\"/kaggle/input\")\n",
    "\n",
    "dataset_dir = os.path.join(cwd, 'ann-and-dl-vqa/dataset_vqa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': '2',\n",
       " 'image_filename': 'CLEVR_train_000000.png',\n",
       " 'question': 'How many other things are there of the same shape as the tiny cyan matte object?'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207594\n",
      "51898\n",
      "51898\n",
      "259492\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "#open Dataset from directory\n",
    "with open(os.path.join(dataset_dir,'train_data.json'), 'r') as f:\n",
    "    train_data_jsonload = json.load(f)\n",
    "f.close()\n",
    "train_data = train_data_jsonload.get(\"questions\")\n",
    "\n",
    "#print(train_data)\n",
    "\n",
    "#Qui ho inserito il validation split. NB: dobbiamo settare per bene e coerentemente tutte le dimensioni di length max + padding (nella parte di tokenizer è un puttanaio, va ripulito). \n",
    "#Al momento se inserisco il validation split, la lunghezza massima si riduce a 40 (la domanda lunga 41 finisce nel validation probabilmente) e di conseguenza nel processo di padding delle stringhe\n",
    "#paddo la lunghezza fino a 40, che va in conflitto con l'input della rete che si aspetta una lunghezza fissa di 41 (che è quella giusta)\n",
    "\n",
    "train_data[0]\n",
    "dataset_size=len(train_data)\n",
    "\n",
    "train_size = round((dataset_size/100)*80)\n",
    "print(train_size)\n",
    "\n",
    "validation_size = dataset_size-train_size\n",
    "print(validation_size)\n",
    "\n",
    "validation_data = train_data[train_size:]\n",
    "print(len(validation_data))\n",
    "\n",
    "train_data2=train_data[:train_size]\n",
    "print(len(train_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printo la mia domanda più lunga\n",
      "What number of objects are either brown things that are on the right side of the tiny brown metal cylinder or large brown matte cubes that are on the right side of the large purple rubber cylinder?\n",
      "testing length: 197\n",
      "printo la mia domanda più lunga tokenizzata\n",
      "[[], [], [27], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [27], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [27], [], [], [27], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [27], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [27], [], [], [], [], [], [], [], [], [], [], [], [27], [], [], [], [], [], [], [], [], [], [], [], [], [27], [], [], [27], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [27], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []]\n",
      "printo test:\n",
      "[[13, 14, 2, 9, 3, 45, 36, 7, 10, 3, 56, 1, 40, 57, 2, 1, 16, 36, 30, 26, 23, 20, 36, 19, 60, 10, 3, 56, 1, 40, 57, 2, 1, 20, 32, 18, 26]]\n",
      "printo la lunghezza di test\n",
      "37\n",
      "vocab size:\n",
      "71\n",
      "word_counts:\n",
      "OrderedDict([('how', 82962), ('many', 82962), ('other', 60726), ('things', 112901), ('are', 221072), ('there', 138746), ('of', 227440), ('the', 416141), ('same', 125584), ('shape', 31306), ('as', 125584), ('tiny', 68664), ('cyan', 39532), ('matte', 66977), ('object', 66149), ('gray', 38945), ('on', 23749), ('right', 35455), ('side', 23749), ('small', 68481), ('rubber', 67078), ('cube', 26681), ('behind', 35245), ('large', 66161), ('brown', 39464), ('thing', 76590), ('left', 35425), ('any', 57284), ('that', 91280), ('have', 28261), ('size', 31364), ('shiny', 45041), ('sphere', 27034), ('cubes', 20831), ('yellow', 39557), ('block', 26793), ('green', 38622), ('blue', 39543), ('what', 82444), ('number', 82444), ('red', 39172), ('spheres', 20890), ('is', 107830), ('cylinder', 53570), ('a', 47299), ('metal', 44897), ('cylinders', 41034), ('in', 35182), ('front', 35182), ('it', 23752), ('ball', 26639), ('balls', 20667), ('metallic', 45188), ('or', 63214), ('big', 65783), ('blocks', 20802), ('color', 31466), ('purple', 39664), ('objects', 101680), ('made', 8724), ('material', 31448), ('visible', 2620), ('both', 3962), ('to', 23669), ('and', 7932), ('another', 2705), ('has', 17361), ('either', 31751), ('anything', 10550), ('else', 10550)])\n",
      "document_count:\n",
      "259492\n",
      "word_indexes:\n",
      "{'the': 1, 'of': 2, 'are': 3, 'there': 4, 'same': 5, 'as': 6, 'things': 7, 'is': 8, 'objects': 9, 'that': 10, 'how': 11, 'many': 12, 'what': 13, 'number': 14, 'thing': 15, 'tiny': 16, 'small': 17, 'rubber': 18, 'matte': 19, 'large': 20, 'object': 21, 'big': 22, 'or': 23, 'other': 24, 'any': 25, 'cylinder': 26, 'a': 27, 'metallic': 28, 'shiny': 29, 'metal': 30, 'cylinders': 31, 'purple': 32, 'yellow': 33, 'blue': 34, 'cyan': 35, 'brown': 36, 'red': 37, 'gray': 38, 'green': 39, 'right': 40, 'left': 41, 'behind': 42, 'in': 43, 'front': 44, 'either': 45, 'color': 46, 'material': 47, 'size': 48, 'shape': 49, 'have': 50, 'sphere': 51, 'block': 52, 'cube': 53, 'ball': 54, 'it': 55, 'on': 56, 'side': 57, 'to': 58, 'spheres': 59, 'cubes': 60, 'blocks': 61, 'balls': 62, 'has': 63, 'anything': 64, 'else': 65, 'made': 66, 'and': 67, 'both': 68, 'another': 69, 'visible': 70}\n",
      "Max question length: 41\n",
      "max length tokenized\n",
      "[4, 8, 27, 17, 39, 30, 51, 10, 8, 56, 1, 40, 57, 2, 1, 20, 15, 10, 8, 56, 1, 41, 57, 2, 1, 35, 18, 52, 3, 4, 25, 17, 37, 19, 31, 10, 3, 43, 44, 2, 55]\n"
     ]
    }
   ],
   "source": [
    "#Qui creo la lista di domande, per intera, sulla quale usare il tokenizer\n",
    "#varie print e cazzate di testing\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "questions_list =list() #lista contenente tutte le domande \n",
    "for element in train_data:\n",
    "    questions_list.append(element.get(\"question\"))\n",
    "    #print(element.get(\"question\"))\n",
    "    \n",
    "#print('printo la mia lista di domande')\n",
    "#print(questions_list)\n",
    "\n",
    "#Preparing data with tokenizer\n",
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts(questions_list)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "print('printo la mia domanda più lunga')\n",
    "longest_question=max(questions_list, key=len)\n",
    "print(longest_question)\n",
    "\n",
    "max_ita_length = max(len(sentence) for sentence in questions_list)\n",
    "print('testing length:',max_ita_length)\n",
    "longest_question_tokenized = tokenizer.texts_to_sequences(longest_question)\n",
    "print('printo la mia domanda più lunga tokenizzata')\n",
    "print(longest_question_tokenized)\n",
    "\n",
    "test_list = list()\n",
    "test_list.append('What number of objects are either brown things that are on the right side of the tiny brown metal cylinder or large brown matte cubes that are on the right side of the large purple rubber cylinder?')\n",
    "test=tokenizer.texts_to_sequences(test_list) #texts_to_sequences ti aspetta una list di stringhe, credo \n",
    "print('printo test:')\n",
    "print(test)\n",
    "\n",
    "print('printo la lunghezza di test')\n",
    "print(len(test[0]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"vocab size:\")\n",
    "print(vocab_size)\n",
    "\n",
    "print(\"word_counts:\")\n",
    "print(tokenizer.word_counts) #mi printa le parole e il numero di volte che sono apparse in totale \n",
    "\n",
    "print(\"document_count:\")\n",
    "print(tokenizer.document_count)\n",
    "\n",
    "print(\"word_indexes:\")\n",
    "print(tokenizer.word_index)#printa la parola e l'indice che gli è stato associato\n",
    "\n",
    "question_tokenized = tokenizer.texts_to_sequences(questions_list)\n",
    "\n",
    "ita_wtoi = tokenizer.word_index\n",
    "#print('Total italian words:', len(ita_wtoi))\n",
    "\n",
    "max_question_length = max(len(sentence) for sentence in question_tokenized)\n",
    "print('Max question length:', max_question_length)\n",
    "\n",
    "longest_question=max(question_tokenized, key=len)\n",
    "print('max length tokenized')\n",
    "print(longest_question)\n",
    "#la lunghezza massima di una domanda è di 41 parole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ImageDataGenerator\n",
    "# ------------------\n",
    "#Per la parte di stringhe, usare tokenizer. Prima estriamo TUTTE le domandee su di esse runniamo \n",
    "#tokenizer = Tokenizer()\n",
    "#tokenizer.fit_on_texts(text)\n",
    "#e otteniamo la tokenizzazione di tutte le parole uniche nelle nostre domande.\n",
    "#Una volta fatto cio, possiamo passare tranquillamente al generator usando, per ogni stringa generata dal generator il metodo sequences = tokenizer.texts_to_sequences(question)\n",
    "#che returna la stessa stringa ma con degli interi che indicano le parole.\n",
    "#Fonte: https://machinelearningmastery.com/how-to-develop-a-word-level-neural-language-model-in-keras/\n",
    "\n",
    "#NB: Da verificare se non c'è da applicare prima un text processing (rimozione punteggiatura,maiuscole ecc...), che però possiamo embeddare nel tokenizer in teoria \n",
    "#-----------------\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "img_directory= os.path.join(dataset_dir, \"train\")\n",
    "import cv2 \n",
    "\n",
    "thisdict = {\n",
    "  '0': 0,\n",
    "  '1': 1,\n",
    " '10': 2,\n",
    "  '2': 3,\n",
    "  '3': 4,\n",
    "  '4': 5,\n",
    "  '5': 6,\n",
    "  '6': 7,\n",
    "  '7': 8,\n",
    "  '8': 9,\n",
    "  '9': 10,\n",
    " 'no': 11,\n",
    "'yes': 12\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def get_image(question):\n",
    "    image_name = question.get(\"image_filename\")\n",
    "    img = cv2.imread(os.path.join(img_directory, image_name))\n",
    "    return(img)\n",
    "\n",
    "def get_question(question):\n",
    "    question_text = question.get(\"question\")\n",
    "    return(question_text)\n",
    "\n",
    "def question_to_token(question):\n",
    "    question_list = list()\n",
    "    question_list.append(question)\n",
    "    question_token_list = tokenizer.texts_to_sequences(question_list)\n",
    "    return(question_token_list[0])\n",
    "\n",
    "def padding(question_token):\n",
    "    # Pad to max question length\n",
    "    question_token_list = list()\n",
    "    question_token_list.append(question_token)\n",
    "    question_padded_list = pad_sequences(question_token_list, maxlen=max_question_length, padding='post')\n",
    "    return(question_padded_list[0])\n",
    "\n",
    "def preprocess_question(question):\n",
    "    question_tokenized = question_to_token(question)\n",
    "    question_padded = padding(question_tokenized)\n",
    "    return(question_padded)\n",
    "\n",
    "\n",
    "def get_output(question):\n",
    "    question_answer = question.get(\"answer\")\n",
    "    x = thisdict[question_answer]\n",
    "    return(x)\n",
    "\n",
    "def preprocess_input(image):\n",
    "    \"\"\"--- Rescale Image\n",
    "    --- Rotate Image\n",
    "    --- Resize Image\n",
    "    --- Flip Image\n",
    "    --- PCA etc. \"\"\"   \n",
    "    return(image)\n",
    "\n",
    "def image_generator(data, batch_size = 64):\n",
    "    \n",
    "    while True:\n",
    "        # Select files (paths/indices) for the batch\n",
    "        batch_questions = np.random.choice(a = data, \n",
    "                                         size = batch_size)\n",
    "        batch_input = []\n",
    "        batch_output = [] \n",
    "        batch_input_image=[]\n",
    "        batch_input_question=[]\n",
    "        \n",
    "        # Read in each input, perform preprocessing and get labels\n",
    "        for input_element in batch_questions:\n",
    "            input_question = get_question(input_element)\n",
    "            input_question_preprocessed = preprocess_question(input_question)\n",
    "            input_image = get_image(input_element)\n",
    "            output = get_output(input_element) \n",
    "            input_question_preprocessed\n",
    "            batch_input_image += [input_image]\n",
    "            batch_input_question += [input_question_preprocessed]\n",
    "            batch_output += [ output ]\n",
    "          # Return a tuple of (input,output) to feed the network\n",
    "        batch_x_image = np.array( batch_input_image )\n",
    "        batch_x_question = np.array( batch_input_question )\n",
    "        batch_y = np.array( batch_output )\n",
    "        yield( [batch_x_image,batch_x_question], batch_y )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import Keras \n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "\n",
    "# img shape\n",
    "img_h = 320\n",
    "img_w = 480\n",
    "# ----------------------\n",
    "EMBEDDING_SIZE = 128\n",
    "\n",
    "# Define CNN for Image Input\n",
    "vision_model = Sequential()\n",
    "vision_model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(img_h, img_w, 3))) #Probabile errore di dimensioni qui \n",
    "vision_model.add(MaxPooling2D((2, 2)))\n",
    "vision_model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "vision_model.add(MaxPooling2D((2, 2)))\n",
    "vision_model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "vision_model.add(MaxPooling2D((2, 2)))\n",
    "vision_model.add(Flatten())\n",
    "\n",
    "\n",
    "\n",
    "image_input = Input(shape=(img_h, img_w, 3))\n",
    "encoded_image = vision_model(image_input)\n",
    "\n",
    "# Define RNN for language input\n",
    "question_input = Input(shape=[41], dtype='int32')\n",
    "embedded_question = Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=EMBEDDING_SIZE, input_length=41)(question_input)\n",
    "hidden_layer = LSTM(128,return_sequences=True)(embedded_question)\n",
    "encoded_question = LSTM(128)(hidden_layer)\n",
    "\n",
    "\n",
    "# Combine CNN and RNN to create the final model\n",
    "merged = tf.keras.layers.concatenate([encoded_question, encoded_image])\n",
    "intermediate = Dense(256, activation='relu')(merged)\n",
    "output = Dense(13, activation='softmax')(intermediate)\n",
    "vqa_model = Model(inputs=[image_input, question_input], outputs=output)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Early Stopping\n",
    "# --------------\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "callbacks=[]\n",
    "early_stop = False\n",
    "if early_stop:\n",
    "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20)\n",
    "    callbacks.append(es_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['accuracy']\n",
    "vqa_model.compile(loss='sparse_categorical_crossentropy',metrics= metrics, optimizer = 'rmsprop')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 41)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 41, 128)      9088        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 41, 128)      131584      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 320, 480, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 128)          131584      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 614400)       370816      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 614528)       0           lstm_1[0][0]                     \n",
      "                                                                 sequential[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          157319424   concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 13)           3341        dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 157,965,837\n",
      "Trainable params: 157,965,837\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "vqa_model.summary()\n",
    "#plot_model(vqa_model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vqa_model.fit_generator(generator=image_generator(train_data2), callbacks=callbacks,validation_data=image_generator(validation_data), validation_steps=30, epochs=80, steps_per_epoch=30)  #fix this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor question in test_data:\\n    question_string=preprocess_question(get_question(question))\\n    image = get_image(question)\\n    x=[image,question_string]\\n    #print('printo x')\\n    #print(x)\\n    #x.shape\\n    #https://stackoverflow.com/questions/41563720/error-when-checking-model-input-expected-convolution2d-input-1-to-have-4-dimens\\n    image = np.expand_dims(image, axis=0)\\n    out_softmax = vqa_model.predict(x=(image,np.array([question_string])))\\n    print(out_softmax) \\n    out_softmax =  np.argmax(out_softmax)\\n    print('printo index')\\n    print(out_softmax)\\n    #out_softmax = np.asscalar(out_softmax)\\n    #print(out_softmax)\\n    #print('printo il valore di question')\\n    #print(question)\\n    #da correggere, la variabile name non esiste. Che indice devo usare? \\n    results[question.get('question_id')] = out_softmax\\ncreate_csv(results)\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import operator\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "def create_csv(results, results_dir='./'):\n",
    "    csv_fname = 'results_'\n",
    "    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
    "    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n",
    "        f.write('Id,Category\\n')\n",
    "        for key, value in results.items():\n",
    "            f.write(str(key) + ',' + str(value) + '\\n')\n",
    "\n",
    "#open Dataset from directory\n",
    "with open(os.path.join(dataset_dir,'test_data.json'), 'r') as f:\n",
    "    test_data_jsonload = json.load(f)\n",
    "    f.close()\n",
    "test_data = test_data_jsonload.get(\"questions\")\n",
    "\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "IMG_DIM = (320, 480)\n",
    "test_img_directory=os.path.join(dataset_dir, 'test')\n",
    "import cv2\n",
    "def get_image(question):\n",
    "    image_name = question.get(\"image_filename\")\n",
    "    img = cv2.imread(os.path.join(test_img_directory, image_name))\n",
    "    return(img)\n",
    "def get_question(question):\n",
    "    question_text = question.get(\"question\")\n",
    "    return(question_text)\n",
    "def question_to_token(question):\n",
    "    question_list = list()\n",
    "    question_list.append(question)\n",
    "    question_token_list = tokenizer.texts_to_sequences(question_list)\n",
    "    return(question_token_list[0])\n",
    "def padding(question_token):\n",
    "    # Pad to max question length\n",
    "    question_token_list = list()\n",
    "    question_token_list.append(question_token)\n",
    "    question_padded_list = pad_sequences(question_token_list, maxlen=max_question_length, padding='post')\n",
    "    return(question_padded_list[0])\n",
    "def preprocess_question(question):\n",
    "    question_tokenized = question_to_token(question)\n",
    "    question_padded = padding(question_tokenized)\n",
    "    return(question_padded)\n",
    "results={}\n",
    "index=0\n",
    "\"\"\"\n",
    "for question in test_data:\n",
    "    question_string=preprocess_question(get_question(question))\n",
    "    image = get_image(question)\n",
    "    x=[image,question_string]\n",
    "    #print('printo x')\n",
    "    #print(x)\n",
    "    #x.shape\n",
    "    #https://stackoverflow.com/questions/41563720/error-when-checking-model-input-expected-convolution2d-input-1-to-have-4-dimens\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    out_softmax = vqa_model.predict(x=(image,np.array([question_string])))\n",
    "    print(out_softmax) \n",
    "    out_softmax =  np.argmax(out_softmax)\n",
    "    print('printo index')\n",
    "    print(out_softmax)\n",
    "    #out_softmax = np.asscalar(out_softmax)\n",
    "    #print(out_softmax)\n",
    "    #print('printo il valore di question')\n",
    "    #print(question)\n",
    "    #da correggere, la variabile name non esiste. Che indice devo usare? \n",
    "    results[question.get('question_id')] = out_softmax\n",
    "create_csv(results)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
